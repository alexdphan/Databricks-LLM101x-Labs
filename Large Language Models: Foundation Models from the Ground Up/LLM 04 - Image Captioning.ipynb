{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d971fb7-1794-4fb7-82a8-41b2a9942db2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d57d9f86-8a7b-4225-9ad9-3098e44fd2ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Image Captioning Model\n",
    "In the realm of multi-modal large language models (MLLMs), image-to-text and text-to-image models are among one of the most commonly seen applications. Can we generate a caption given an image and vice versa? We saw in the presentation that transformer architectures are general sequence-processing architectures that can process both images and text. In this lesson, we will learn how to build a vision-text transformer architecture yourself and compare the DIY-transformer performance against a pre-trained image captioning model. \n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Connect pretrained vision and text models as a single transformer architecture for image captioning\n",
    "1. Train your image captioning model\n",
    "1. Qualitatively inspect the quality of the caption generated\n",
    "1. Compare the output with an pretrained image captioning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df157eb6-eeec-48f3-b6e3-4f8a2a015d98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd2bf72-f707-48bb-ae18-66677e3f41f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| enumerating serving endpoints...found 0...(0 seconds)\n| No action taken\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/llm-foundation-models/v01-raw\"\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| removing extra file: /models/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/tokenizer.json...(0 seconds)\n| fixed 1 issue...(3 seconds total)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing lab testing framework.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nUsing the \"default\" schema.\n\nPredefined paths variables:\n| DA.paths.working_dir: /dbfs/mnt/dbacademy-users/labuser4574468@vocareum.com/llm-foundation-models\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/labuser4574468@vocareum.com/llm-foundation-models/database.db\n| DA.paths.datasets:    /dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw\n\nSetup completed (9 seconds)\n\nThe models developed or used in this course are for demonstration and learning purposes only.\nModels may occasionally output offensive, inaccurate, biased information, or harmful instructions.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c57682-6dd7-4a1c-845d-18b5a74602a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We are going to use `sbu_captions` as our dataset to train our own image captioning model. \n",
    "\n",
    "`sbu_captions` contains 1 million pairs of image urls and captions. Visit [this link](https://huggingface.co/datasets/sbu_captions) to view their dataset on Hugging Face Datasets hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66751aea-aa98-4b55-92b4-2d2165b29ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b2390dac3042e8bdc50c8ba2e3084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2193e480120e4ddd8162343712e3e9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe4e0e37af84ee89d7d67c277e68efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sbu_captions/default to /root/.cache/huggingface/datasets/sbu_captions/default/0.0.0/0c994175c0b31f384f0b9a6aa51c5c9969c468df4c3d33a52074686ea51ee684...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f007bf01425848b58ecf3dc6b305728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210b72bce71f46ee92a778312921fe1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sbu_captions downloaded and prepared to /root/.cache/huggingface/datasets/sbu_captions/default/0.0.0/0c994175c0b31f384f0b9a6aa51c5c9969c468df4c3d33a52074686ea51ee684. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_url', 'user_id', 'caption'],\n",
       "    num_rows: 1000000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required Libraries:\n",
    "# - `datasets`: HuggingFace's datasets library for loading datasets\n",
    "\n",
    "# Import the 'load_dataset' function from the 'datasets' library\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SBU Captions dataset and shuffle it using a seed value of 42\n",
    "# The 'split=\"train\"' argument specifies that only the training split of the dataset is loaded\n",
    "# The 'shuffle(seed=42)' function shuffles the dataset in a reproducible manner using the specified seed\n",
    "data = load_dataset(\"sbu_captions\", split=\"train\").shuffle(seed=42)\n",
    "\n",
    "# Display the shuffled dataset\n",
    "# Useful for debugging and initial exploration of the dataset\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e85e46d-afaf-4fa7-a12d-6676dd6a233f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Initialize an image-to-text model\n",
    "\n",
    "In the following section, we are going to use [Vision Encoder Decoder Model](https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder) to initialize our image-to-text model. The encoder would be a transformer-based vision model to process the images and the decoder is a language model to generate the caption. Then, we will connect both the vision and language model together and further train the vision-language model on a subset of `sbu_captions`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e8f941-4a9c-4ef4-9f12-14bd32a18826",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define data processing function\n",
    "\n",
    "First, we will need to have a function to properly process our training dataset that contains the image urls and respective captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd475c70-4bf9-44e9-b36f-6cac5842dee4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Required Libraries:\n",
    "# - torch: For tensor operations\n",
    "# - PIL: For image processing\n",
    "# - requests: For fetching images from URLs\n",
    "# - HuggingFace Transformers: For tokenization and feature extraction\n",
    "\n",
    "class ProcessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A class to process a dataset for a multimodal (vision + text) model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (Pandas DataFrame): A DataFrame containing 'image_url' and 'caption' columns.\n",
    "    - tokenizer: A tokenizer object for text processing.\n",
    "    - feature_extractor: A feature extraction object for image processing.\n",
    "    - decoder_max_length (int): Maximum length of output caption.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, tokenizer, feature_extractor, decoder_max_length=20):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.decoder_max_length = decoder_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch and preprocess the image and text at a given index.\n",
    "        \n",
    "        Parameters:\n",
    "        - idx (int): Index of the data to fetch.\n",
    "        \n",
    "        Returns:\n",
    "        - encoding (dict): A dictionary containing processed image and text data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Fetch image URL and caption from DataFrame\n",
    "        img_path = self.df[\"image_url\"][idx]\n",
    "        caption = self.df[\"caption\"][idx]\n",
    "        \n",
    "        # Fetch image from URL\n",
    "        response = requests.get(img_path)\n",
    "        # TODO: Add error handling for failed requests\n",
    "        \n",
    "        # Process image\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Extract features from the image\n",
    "        # 'pt' indicates that PyTorch tensors are returned\n",
    "        pixel_values = self.feature_extractor(image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Process caption text\n",
    "        labels = self.tokenizer(\n",
    "            caption,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.decoder_max_length\n",
    "        ).input_ids\n",
    "        \n",
    "        # Prepare output encoding\n",
    "        encoding = {\n",
    "            \"pixel_values\": pixel_values.squeeze(),  # Remove singleton dimensions\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "        \n",
    "        return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ebf15a3-dbff-4f22-8607-caea7099b8ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Initialize tokenizer and image feature extractor\n",
    "\n",
    "Next, we will initialize our tokenizer to process text and feature extractor to process images respectively. After this, we are ready to pass our training dataset for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a58b56-b4cc-4366-8179-6ef3a271554c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b638d98a4f124afdb03a88de10da9c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/huggingface_hub/file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in /dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw/models. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n  warnings.warn(message)\n/databricks/python/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries:\n",
    "# - transformers: HuggingFace's Transformers library for NLP and computer vision models\n",
    "\n",
    "# Import the necessary classes from the 'transformers' library\n",
    "from transformers import GPT2TokenizerFast, ViTFeatureExtractor\n",
    "\n",
    "# Initialize the GPT-2 tokenizer using a pre-trained model\n",
    "# The 'cache_dir' argument specifies the directory to store the downloaded pre-trained model\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    cache_dir=DA.paths.datasets+\"/models\"\n",
    ")\n",
    "\n",
    "# Add a padding token to the GPT-2 tokenizer\n",
    "# GPT-2 originally does not have a pad token, so we set it to be the same as the EOS (end-of-sentence) token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Initialize the Vision Transformer (ViT) feature extractor using a pre-trained model\n",
    "# The 'cache_dir' argument specifies the directory to store the downloaded pre-trained model (Vision Transformer (base-sized model))\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\", \n",
    "    cache_dir=DA.paths.datasets+\"/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aea5de4e-f207-4c47-9abb-f9b95722188b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Required Libraries:\n",
    "# Assume that the 'ProcessDataset' class, 'tokenizer', and 'feature_extractor' have been previously defined.\n",
    "# 'data' is a dataset loaded via some data loading mechanism (e.g., HuggingFace datasets library).\n",
    "\n",
    "# Initialize the training dataset using the ProcessDataset class\n",
    "# - df=data[:2000]: We are using the first 2000 samples from the 'data' DataFrame for training.\n",
    "# - tokenizer=tokenizer: We pass in the previously initialized GPT-2 tokenizer for text tokenization.\n",
    "# - feature_extractor=feature_extractor: We pass in the previously initialized ViT feature extractor for image processing.\n",
    "train_dataset = ProcessDataset(\n",
    "    df=data[:2000],  # Use the first 2000 rows of the DataFrame 'data' for the training dataset\n",
    "    tokenizer=tokenizer,  # Use the GPT-2 tokenizer defined earlier for text tokenization\n",
    "    feature_extractor=feature_extractor  # Use the ViT feature extractor defined earlier for image feature extraction\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c390b6-7d35-4b2e-87bd-0a87d7321429",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using VisionEncoderDecoder \n",
    "\n",
    "Here, we will finally use `VisionEncoderDecoder` to connect our pretrained image and text models of choice. \n",
    "\n",
    "You might see in the output that some weights of the GPT2 model are not initialized from the model checkpoint; from HuggingFace: `You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.` For the best performance, we should ideally fine-tune this decoder on our own dataset separately and load the fine-tuned decoder. However, for simplicity's sake, we are simply going to use the model as is, and fine-tune the image-captioning model as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0775b0f6-f299-4b63-b207-dd86b177d52e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fad730079d4d31acd7835950c9a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaebed60c10f4d71803a591e5e1cc662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e1f6bffa6545d5a1efdb7b23a8b4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbc454a8ed54d3a8df2271d2230ff62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.5.crossattention.q_attn.weight', 'h.6.ln_cross_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.3.crossattention.masked_bias', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.5.ln_cross_attn.weight', 'h.0.ln_cross_attn.weight', 'h.11.crossattention.masked_bias', 'h.1.crossattention.q_attn.weight', 'h.0.crossattention.masked_bias', 'h.3.crossattention.bias', 'h.9.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.10.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.weight', 'h.7.ln_cross_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.1.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.8.crossattention.masked_bias', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.masked_bias', 'h.3.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.weight', 'h.7.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.5.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.5.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.10.ln_cross_attn.weight', 'h.8.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.7.crossattention.q_attn.weight', 'h.10.crossattention.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.weight', 'h.4.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.1.crossattention.masked_bias', 'h.6.crossattention.bias', 'h.11.ln_cross_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.4.crossattention.masked_bias', 'h.4.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.weight', 'h.11.crossattention.c_proj.weight', 'h.0.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.8.ln_cross_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.4.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.2.crossattention.masked_bias', 'h.6.crossattention.c_proj.bias', 'h.9.crossattention.bias', 'h.7.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.1.crossattention.bias', 'h.7.crossattention.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.weight', 'h.8.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67d1a97aae44be393b8036abf73e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required Libraries:\n",
    "# - transformers: HuggingFace's Transformers library for creating encoder-decoder models.\n",
    "\n",
    "# Import the VisionEncoderDecoderModel class from the 'transformers' library\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "# Initialize the VisionEncoderDecoderModel using pre-trained models for both the encoder and decoder\n",
    "# - encoder_pretrained_model_name_or_path: Specifies the pre-trained model to use for the encoder (Vision Transformer).\n",
    "# - decoder_pretrained_model_name_or_path: Specifies the pre-trained model to use for the decoder (GPT-2).\n",
    "# - tie_encoder_decoder: If set to True, ties the encoder and decoder weights together for more efficient training.\n",
    "# - cache_dir: Specifies the directory to cache the downloaded pre-trained models.\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder_pretrained_model_name_or_path=\"google/vit-base-patch16-224-in21k\",  # Use Vision Transformer as the encoder\n",
    "    decoder_pretrained_model_name_or_path=\"gpt2\",  # Use GPT-2 as the decoder\n",
    "    tie_encoder_decoder=True,  # Tie encoder and decoder parameters for more efficient training\n",
    "    cache_dir=DA.paths.datasets+\"/models\"  # Cache the downloaded models in the specified directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c31221-d437-4259-8707-10514d7b51aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Update GPT-2 Configuration for Encoder-Decoder Model:\n",
    "# GPT-2 uses bos (beginning of sentence) and eos (end of sentence) tokens,\n",
    "# but it doesn't natively support decoder_start or pad tokens. We configure these manually.\n",
    "\n",
    "# Set the decoder's start token ID to be the same as the bos_token_id from the tokenizer\n",
    "# This is used to initiate the decoding process.\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "# Set the padding token ID to be the same as the pad_token_id from the tokenizer\n",
    "# Padding tokens are used to fill in sequences to a uniform length.\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# Explicitly set the end-of-sentence token ID, even though it's usually set by default in GPT-2\n",
    "# This is used to signify the end of a generated sequence.\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Additional Configuration Adjustments:\n",
    "\n",
    "# Synchronize the vocab size between the model configuration and the decoder\n",
    "# Ensures that the decoder uses the same vocabulary size as defined in its own configuration.\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "# Enable early stopping in the beam search to improve decoding efficiency\n",
    "# Stops the search when at least `num_beams` sentences are finished per batch.\n",
    "model.config.early_stopping = True\n",
    "# Set no_repeat_ngram_size to prevent the repetition of n-grams within the generated text\n",
    "# An n-gram of size 3 means any sequence of 3 words cannot be repeated in the generated text.\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "# Apply a length penalty for longer sequences in the beam search\n",
    "# A factor of 2.0 discourages the model from generating overly short sequences.\n",
    "model.config.length_penalty = 2.0\n",
    "\n",
    "# Decoder-Specific Settings:\n",
    "\n",
    "# Set the number of beams for beam search in the decoder\n",
    "# More beams increases the chances of finding a more accurate sequence but is computationally expensive.\n",
    "model.decoder.num_beams = 4\n",
    "# Set the maximum sequence length for the decoder's output\n",
    "# Limits the length of generated sequences to 20 tokens.\n",
    "model.decoder.max_length = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2f960b8-9e4a-4bef-ae4f-feeda5f9ae2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train image-captioning model\n",
    "\n",
    "Recall that you have seen `data_collator` in Module 2 before. \n",
    "\n",
    "As a refresher, data collators help us form batches of inputs to pass in to the model for training. Go [here](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#data-collator) for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e076556e-4896-4097-98ac-35024423fddb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_EPOCHS = 20\n",
    "\n",
    "output_directory = os.path.join(DA.paths.working_dir, \"captioning_outputs\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    do_train=True,\n",
    "    num_train_epochs=TRAIN_EPOCHS, # number of passes to see the entire dataset \n",
    "    overwrite_output_dir=True,\n",
    "    no_cuda=True, # Not using GPU\n",
    "    dataloader_pin_memory=False # this specifies whether you want to pin memory in data loaders or not\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    tokenizer=feature_extractor,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fa6f72f-0b06-4474-9f4c-dccee3503b39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Note: You might notice that this cells triggers a whole new MLflow run. [MLflow](https://mlflow.org/docs/latest/index.html) is an open source tool that helps to manage end-to-end machine learning lifecycle, including experiment tracking, ML code packaging, and model deployment. You can read more about [LLM tracking here](https://mlflow.org/docs/latest/llm-tracking.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "906a8953-1869-4770-b666-3e63a6ccddcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\n",
       "\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n",
       "\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m socket\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgetaddrinfo returns an empty list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n",
       "\u001B[1;32m     84\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n",
       "\u001B[0;32m---> 85\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sock\n",
       "\n",
       "\u001B[0;31mTimeoutError\u001B[0m: [Errno 110] Connection timed out\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mConnectTimeoutError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n",
       "\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n",
       "\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n",
       "\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n",
       "\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n",
       "\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n",
       "\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 398\u001B[0m         \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhttplib_request_kw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    400\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n",
       "\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n",
       "\u001B[1;32m    402\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:239\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers)\u001B[0m\n",
       "\u001B[1;32m    238\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_default_user_agent()\n",
       "\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1283\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1282\u001B[0m \u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1329\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1328\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m-> 1329\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1278\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n",
       "\u001B[0;32m-> 1278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1038\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n",
       "\u001B[0;32m-> 1038\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m   1041\u001B[0m \n",
       "\u001B[1;32m   1042\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:976\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n",
       "\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n",
       "\u001B[0;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m--> 205\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_conn(conn)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:179\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n",
       "\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeoutError(\n",
       "\u001B[1;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m timed out. (connect timeout=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    182\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout),\n",
       "\u001B[1;32m    183\u001B[0m     )\n",
       "\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "\u001B[0;31mConnectTimeoutError\u001B[0m: (<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)')\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n",
       "\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n",
       "\u001B[0;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n",
       "\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n",
       "\u001B[1;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n",
       "\u001B[0;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n",
       "\u001B[1;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n",
       "\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n",
       "\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n",
       "\u001B[1;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
       "\n",
       "\u001B[0;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /2551/4088062107_97bf024b38.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1542565039235819>:4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Same errors begin here because of stupid fetching flickr photos\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# ConnectTimeout: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:434\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    420\u001B[0m     active_session_failed\n",
       "\u001B[1;32m    421\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    428\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n",
       "\u001B[1;32m    429\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n",
       "\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    431\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    432\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    433\u001B[0m     ):\n",
       "\u001B[0;32m--> 434\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n",
       "\u001B[1;32m    437\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n",
       "\u001B[1;32m    438\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/huggingface_patches/transformers.py:54\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patched_fit_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     52\u001B[0m call_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 54\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     55\u001B[0m     call_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/transformers/trainer.py:1664\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n",
       "\u001B[1;32m   1661\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n",
       "\u001B[1;32m   1662\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n",
       "\u001B[1;32m   1663\u001B[0m )\n",
       "\u001B[0;32m-> 1664\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1669\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/transformers/trainer.py:1909\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n",
       "\u001B[1;32m   1906\u001B[0m     rng_to_sync \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m   1908\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
       "\u001B[0;32m-> 1909\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(epoch_iterator):\n",
       "\u001B[1;32m   1910\u001B[0m     total_batched_samples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
       "\u001B[1;32m   1911\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rng_to_sync:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n",
       "\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n",
       "\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
       "\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n",
       "\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n",
       "\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n",
       "\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n",
       "\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n",
       "\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n",
       "\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n",
       "\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
       "\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n",
       "\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n",
       "\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
       "\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
       "\n",
       "File \u001B[0;32m<command-1542565039235809>:50\u001B[0m, in \u001B[0;36mProcessDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m caption \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcaption\u001B[39m\u001B[38;5;124m\"\u001B[39m][idx]\n",
       "\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Fetch image from URL\u001B[39;00m\n",
       "\u001B[0;32m---> 50\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# TODO: Add error handling for failed requests\u001B[39;00m\n",
       "\u001B[1;32m     52\u001B[0m \n",
       "\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# Process image\u001B[39;00m\n",
       "\u001B[1;32m     54\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(BytesIO(response\u001B[38;5;241m.\u001B[39mcontent))\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m     63\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n",
       "\u001B[1;32m     64\u001B[0m \n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n",
       "\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n",
       "\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n",
       "\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n",
       "\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n",
       "\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n",
       "\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n",
       "\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n",
       "\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n",
       "\u001B[1;32m    585\u001B[0m }\n",
       "\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n",
       "\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n",
       "\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n",
       "\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n",
       "\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:553\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n",
       "\u001B[1;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ConnectTimeoutError):\n",
       "\u001B[1;32m    551\u001B[0m     \u001B[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001B[39;00m\n",
       "\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, NewConnectionError):\n",
       "\u001B[0;32m--> 553\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeout(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
       "\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ResponseError):\n",
       "\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RetryError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
       "\n",
       "\u001B[0;31mConnectTimeout\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /2551/4088062107_97bf024b38.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m socket\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgetaddrinfo returns an empty list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     84\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m---> 85\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sock\n\n\u001B[0;31mTimeoutError\u001B[0m: [Errno 110] Connection timed out\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mConnectTimeoutError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 398\u001B[0m         \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhttplib_request_kw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:239\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers)\u001B[0m\n\u001B[1;32m    238\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_default_user_agent()\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1283\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1329\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1328\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1329\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1278\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1038\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1038\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1041\u001B[0m \n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:976\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 205\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_conn(conn)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:179\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeoutError(\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m timed out. (connect timeout=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout),\n\u001B[1;32m    183\u001B[0m     )\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketError \u001B[38;5;28;01mas\u001B[39;00m e:\n\n\u001B[0;31mConnectTimeoutError\u001B[0m: (<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)')\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[1;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n\n\u001B[0;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /2551/4088062107_97bf024b38.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-1542565039235819>:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Same errors begin here because of stupid fetching flickr photos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# ConnectTimeout: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:434\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    420\u001B[0m     active_session_failed\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    431\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    432\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    433\u001B[0m     ):\n\u001B[0;32m--> 434\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n\u001B[1;32m    438\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/huggingface_patches/transformers.py:54\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patched_fit_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     52\u001B[0m call_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 54\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     call_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/transformers/trainer.py:1664\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1661\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1662\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1663\u001B[0m )\n\u001B[0;32m-> 1664\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1669\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/transformers/trainer.py:1909\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1906\u001B[0m     rng_to_sync \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1908\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1909\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(epoch_iterator):\n\u001B[1;32m   1910\u001B[0m     total_batched_samples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1911\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rng_to_sync:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\nFile \u001B[0;32m<command-1542565039235809>:50\u001B[0m, in \u001B[0;36mProcessDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     47\u001B[0m caption \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcaption\u001B[39m\u001B[38;5;124m\"\u001B[39m][idx]\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Fetch image from URL\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# TODO: Add error handling for failed requests\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# Process image\u001B[39;00m\n\u001B[1;32m     54\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(BytesIO(response\u001B[38;5;241m.\u001B[39mcontent))\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:553\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ConnectTimeoutError):\n\u001B[1;32m    551\u001B[0m     \u001B[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001B[39;00m\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, NewConnectionError):\n\u001B[0;32m--> 553\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeout(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ResponseError):\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RetryError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\n\u001B[0;31mConnectTimeout\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /2551/4088062107_97bf024b38.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))",
       "errorSummary": "<span class='ansi-red-fg'>ConnectTimeout</span>: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /2551/4088062107_97bf024b38.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0943d2500>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same errors begin here because of stupid fetching flickr photos\n",
    "# ConnectTimeout: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e0d27d4-2004-4c09-b5a0-a877ddba4f4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate caption from an image\n",
    "\n",
    "Now, let's try generating caption from a randomly picked image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "948834de-36bf-4c68-b5b1-08168cf10ede",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\n",
       "\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n",
       "\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m socket\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgetaddrinfo returns an empty list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n",
       "\u001B[1;32m     84\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n",
       "\u001B[0;32m---> 85\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sock\n",
       "\n",
       "\u001B[0;31mTimeoutError\u001B[0m: [Errno 110] Connection timed out\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mConnectTimeoutError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n",
       "\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n",
       "\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n",
       "\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n",
       "\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n",
       "\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n",
       "\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 398\u001B[0m         \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhttplib_request_kw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    400\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n",
       "\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n",
       "\u001B[1;32m    402\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:239\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers)\u001B[0m\n",
       "\u001B[1;32m    238\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_default_user_agent()\n",
       "\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1283\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1282\u001B[0m \u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1329\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1328\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m-> 1329\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1278\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n",
       "\u001B[0;32m-> 1278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:1038\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n",
       "\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n",
       "\u001B[0;32m-> 1038\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m   1041\u001B[0m \n",
       "\u001B[1;32m   1042\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/http/client.py:976\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n",
       "\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n",
       "\u001B[0;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m--> 205\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_conn(conn)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:179\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n",
       "\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeoutError(\n",
       "\u001B[1;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m timed out. (connect timeout=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    182\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout),\n",
       "\u001B[1;32m    183\u001B[0m     )\n",
       "\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "\u001B[0;31mConnectTimeoutError\u001B[0m: (<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)')\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n",
       "\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n",
       "\u001B[0;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n",
       "\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n",
       "\u001B[1;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n",
       "\u001B[0;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n",
       "\u001B[1;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n",
       "\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n",
       "\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n",
       "\u001B[1;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
       "\n",
       "\u001B[0;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1542565039235821>:9\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m test_img_path \u001B[38;5;241m=\u001B[39m test_img[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_url\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Fetch the image content from the URL\u001B[39;00m\n",
       "\u001B[0;32m----> 9\u001B[0m test_img_response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(test_img_path)\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Open and read the image using PIL (Python Imaging Library)\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m test_image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(BytesIO(test_img_response\u001B[38;5;241m.\u001B[39mcontent))\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m     63\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n",
       "\u001B[1;32m     64\u001B[0m \n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n",
       "\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n",
       "\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n",
       "\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n",
       "\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n",
       "\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n",
       "\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n",
       "\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n",
       "\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n",
       "\u001B[1;32m    585\u001B[0m }\n",
       "\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n",
       "\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n",
       "\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n",
       "\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n",
       "\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:553\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n",
       "\u001B[1;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ConnectTimeoutError):\n",
       "\u001B[1;32m    551\u001B[0m     \u001B[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001B[39;00m\n",
       "\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, NewConnectionError):\n",
       "\u001B[0;32m--> 553\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeout(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
       "\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ResponseError):\n",
       "\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RetryError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
       "\n",
       "\u001B[0;31mConnectTimeout\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m socket\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgetaddrinfo returns an empty list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     84\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m---> 85\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sock\n\n\u001B[0;31mTimeoutError\u001B[0m: [Errno 110] Connection timed out\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mConnectTimeoutError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 398\u001B[0m         \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhttplib_request_kw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:239\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers)\u001B[0m\n\u001B[1;32m    238\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_default_user_agent()\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1283\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1329\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1328\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1329\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1278\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:1038\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1038\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1041\u001B[0m \n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n\nFile \u001B[0;32m/usr/lib/python3.10/http/client.py:976\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 205\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_conn(conn)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connection.py:179\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeoutError(\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m timed out. (connect timeout=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout),\n\u001B[1;32m    183\u001B[0m     )\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketError \u001B[38;5;28;01mas\u001B[39;00m e:\n\n\u001B[0;31mConnectTimeoutError\u001B[0m: (<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)')\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[1;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n\n\u001B[0;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-1542565039235821>:9\u001B[0m\n\u001B[1;32m      7\u001B[0m test_img_path \u001B[38;5;241m=\u001B[39m test_img[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_url\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Fetch the image content from the URL\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m test_img_response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(test_img_path)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Open and read the image using PIL (Python Imaging Library)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m test_image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(BytesIO(test_img_response\u001B[38;5;241m.\u001B[39mcontent))\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/requests/adapters.py:553\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ConnectTimeoutError):\n\u001B[1;32m    551\u001B[0m     \u001B[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001B[39;00m\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, NewConnectionError):\n\u001B[0;32m--> 553\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeout(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ResponseError):\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RetryError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\n\u001B[0;31mConnectTimeout\u001B[0m: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))",
       "errorSummary": "<span class='ansi-red-fg'>ConnectTimeout</span>: HTTPConnectionPool(host='static.flickr.com', port=80): Max retries exceeded with url: /33/205540567_b8cab77901.jpg (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fe0949faa70>, 'Connection to static.flickr.com timed out. (connect timeout=None)'))",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the 'requests' library for fetching image data and 'Image' for displaying the image\n",
    "# Assume these libraries have been imported earlier in the code\n",
    "\n",
    "# Select a test image from the dataset at index 2021\n",
    "test_img = data[2021]\n",
    "# Extract the image URL from the test image data\n",
    "test_img_path = test_img[\"image_url\"]\n",
    "# Fetch the image content from the URL\n",
    "test_img_response = requests.get(test_img_path)\n",
    "# Open and read the image using PIL (Python Imaging Library)\n",
    "test_image = Image.open(BytesIO(test_img_response.content))\n",
    "# Display the test image\n",
    "# The 'display' function is assumed to be imported from a library like IPython\n",
    "display(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5a5cf6-c06d-47d7-9ac9-12170b7df3e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1542565039235822>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Generate features from the test image using the feature extractor\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# \"pt\" just mean Pytorch\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m image_features \u001B[38;5;241m=\u001B[39m feature_extractor(test_image, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mpixel_values\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Use the model to generate a caption for the image\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m generated_token_ids \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mgenerate(image_features)[\u001B[38;5;241m0\u001B[39m]\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'test_image' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1542565039235822>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Generate features from the test image using the feature extractor\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# \"pt\" just mean Pytorch\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m image_features \u001B[38;5;241m=\u001B[39m feature_extractor(test_image, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mpixel_values\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Use the model to generate a caption for the image\u001B[39;00m\n\u001B[1;32m      6\u001B[0m generated_token_ids \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mgenerate(image_features)[\u001B[38;5;241m0\u001B[39m]\n\n\u001B[0;31mNameError\u001B[0m: name 'test_image' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'test_image' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate features from the test image using the feature extractor\n",
    "# \"pt\" just mean Pytorch\n",
    "image_features = feature_extractor(test_image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# Use the model to generate a caption for the image\n",
    "generated_token_ids = trainer.model.generate(image_features)[0]\n",
    "\n",
    "# Decode the generated token IDs to a human-readable caption\n",
    "caption = tokenizer.decode(generated_token_ids)\n",
    "\n",
    "# Print a separator and the generated caption\n",
    "print(\"--\" * 20)\n",
    "print(caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4590d1-069a-4ae3-bc85-11f24a3edb30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Hmm, you can see that the caption is not really relevant to the image above. What went wrong? There are two possible reasons: \n",
    "- Parts of our text decoder weights were not loaded from the pretrained checkpoints. So the best approach would have been to train the decoder separately on the training dataset first and load the fine-tuned decoder. \n",
    "- Our image-captioning model needs more fine-tuning time! Try increasing the # of epochs, # of training data samples, and adjust other model hyperaparameters if you'd like. \n",
    "\n",
    "But now you learned how to plug in your own transformer-based models and connect them as an encoder-decoder model! It would definitely be much easier if we use an existing image captioning model instead. Let's do that next!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f80e9a2c-e0f7-467b-a9f3-2b1d1569d94f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What if we use an existing image captioning model instead? \n",
    "\n",
    "Will the caption generated improve and be more relevant? Let's find out! \n",
    "\n",
    "We will be using a new model called `BLIP`, which stands for Bootstrapping Language-Image Pre-training. It's a modeling approach to unify vision-language understanding and generation by [Li et al 2022](https://arxiv.org/abs/2201.12086). It stands out from other vision-language model because: \n",
    "\n",
    ">  Most existing pre-trained models only excel in either understanding-based tasks or generation-based tasks. [...] BLIP effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones.\n",
    "\n",
    "The excerpt above is from the paper's abstract. You can also read briefly about BLIP in the [HuggingFace documentation](https://huggingface.co/Salesforce/blip-image-captioning-base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b528102-019a-416f-bab7-e47137a2c090",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1542565039235825>:10\u001B[0m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# conditional image captioning\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# in many of the initial vision-language models, adding a prefix text like below \"a photo of \" is crucial for models to do well\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# the addition of the prefix text makes the caption generation \"conditional\"\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma photo of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m---> 10\u001B[0m inputs \u001B[38;5;241m=\u001B[39m blip_processor(test_image, text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     12\u001B[0m conditional_output \u001B[38;5;241m=\u001B[39m blip_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConditional output: \u001B[39m\u001B[38;5;124m\"\u001B[39m, blip_processor\u001B[38;5;241m.\u001B[39mdecode(conditional_output[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'test_image' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1542565039235825>:10\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# conditional image captioning\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# in many of the initial vision-language models, adding a prefix text like below \"a photo of \" is crucial for models to do well\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# the addition of the prefix text makes the caption generation \"conditional\"\u001B[39;00m\n\u001B[1;32m      9\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma photo of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 10\u001B[0m inputs \u001B[38;5;241m=\u001B[39m blip_processor(test_image, text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m conditional_output \u001B[38;5;241m=\u001B[39m blip_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConditional output: \u001B[39m\u001B[38;5;124m\"\u001B[39m, blip_processor\u001B[38;5;241m.\u001B[39mdecode(conditional_output[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\n\u001B[0;31mNameError\u001B[0m: name 'test_image' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'test_image' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\", cache_dir=DA.paths.datasets+\"/models\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\", cache_dir=DA.paths.datasets+\"/models\")\n",
    "\n",
    "# conditional image captioning\n",
    "# in many of the initial vision-language models, adding a prefix text like below \"a photo of \" is crucial for models to do well\n",
    "# the addition of the prefix text makes the caption generation \"conditional\"\n",
    "text = \"a photo of\"\n",
    "inputs = blip_processor(test_image, text, return_tensors=\"pt\")\n",
    "\n",
    "conditional_output = blip_model.generate(**inputs)\n",
    "print(\"Conditional output: \", blip_processor.decode(conditional_output[0], skip_special_tokens=True))\n",
    "\n",
    "# unconditional image captioning\n",
    "# in newer model iterations, researchers have found improvements to remove the need of adding a prefix text \n",
    "# therefore, the caption generation is \"unconditional\"\n",
    "# notice that the `text` field is no longer filled out (it's now optional)\n",
    "inputs = blip_processor(test_image, return_tensors=\"pt\")\n",
    "\n",
    "unconditional_output = blip_model.generate(**inputs)\n",
    "print(\"Unconditional output: \", blip_processor.decode(unconditional_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4fd9e1b-84c2-42b8-97e4-9429c68eaf39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now that you have seen how to generate caption from images, we are going to get our hands dirty to play with videos in the lab! You will learn how to perform zero-shot video classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16a4ce7-e43f-4db8-b71e-003ba4e6a12d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LLM 04 - Image Captioning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
